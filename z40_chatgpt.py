import configparser
import json
import os

import openai
import tiktoken
from flask import Flask, request

# è¼‰å…¥ LINE Message API ç›¸é—œå‡½å¼åº«
from linebot import LineBotApi, WebhookHandler
from linebot.models import TextSendMessage  # è¼‰å…¥ TextSendMessage æ¨¡çµ„
from openai import APIError, OpenAI
from transformers import AutoTokenizer

# model_name = "gpt-3.5-turbo-instruct"
model_name = "text-davinci-003"
max_tokens = 2500
encoding = tiktoken.encoding_for_model(model_name)


def ChatGptCommitQuery(msg):
    # è®€å–API
    config = configparser.ConfigParser()
    config.read("../LINEBOT_API_KEY/openai_api.ini")
    key = config.get("openai", "key")
    try:
        # å–å‡ºæ–‡å­—çš„å‰äº”å€‹å­—å…ƒï¼Œè½‰æ›æˆå°å¯«
        # å°‡ç¬¬å…­å€‹å­—å…ƒä¹‹å¾Œçš„è¨Šæ¯ç™¼é€çµ¦ OpenAI
        ai_msg = msg[:6].lower()
        reply_msg = ""
        # å–å‡ºæ–‡å­—çš„å‰äº”å€‹å­—å…ƒæ˜¯ hi ai:
        if ai_msg == "hi ai:":
            msg = msg[6:]
            print(f"æ¸›å°‘tokenå‰={len(encoding.encode(msg))}")
            # è¨­å®štokenä¸Šé™
            if len(encoding.encode(msg)) > max_tokens:
                msg_token = encoding.encode(msg)[:max_tokens]
                print(f"æ¸›å°‘tokenå¾Œ={len(msg_token)}")
                msg = encoding.decode(msg_token)
                # msg = [encoding.decode_single_token_bytes(token) for token in msg_token]
            print(msg)
            # # è¨­å®š OpenAI API é‡‘é‘°
            client = OpenAI(api_key=key)
            response = client.completions.create(
                # model="gpt-3.5-turbo-instruct",
                # model="text-davinci-003",
                model="gpt-3.5-turbo-instruct-0914",
                # å°‡ç¬¬å…­å€‹å­—å…ƒä¹‹å¾Œçš„è¨Šæ¯ç™¼é€çµ¦ OpenAI
                # prompt=msg[6:],
                prompt=msg
                + "\nä»¥ä¸Šæ˜¯åº—å®¶çš„è©•åƒ¹,è«‹ä¾é¤é»åç¨±ä¾†æ•´åˆè©•åƒ¹,ä¸¦'ä½¿ç”¨ç´„150å­—'å®¢è§€ä»‹ç´¹åº—å®¶ã€‚\nå›è¦†çš„æœ€å¾Œè«‹åŠ ä¸Š 'æ¨è–¦åº¦='(ç”¨è©•è«–å…§å®¹çµ¦1~5é¡†æ˜Ÿ,ç”¨â˜…ç¬¦è™Ÿä»£è¡¨ä¸€é¡†æ˜ŸåŠâ˜†ç¬¦è™Ÿä»£è¡¨ç„¡æ˜Ÿ)ã€‚",
                max_tokens=500,
                temperature=0.9,
                frequency_penalty=0.5,
                presence_penalty=0.5,
            )
            # æ¥æ”¶åˆ°å›è¦†è¨Šæ¯å¾Œï¼Œç§»é™¤æ›è¡Œç¬¦è™Ÿ
            msg = response.choices[0].text.replace("\n", "")
            print(msg)
            return msg
        else:
            msg = "å¤±æ•—äº†"
        return msg
    except Exception as e:
        print(f"Error with vendor_id : {e}")
    return "OK"


def ChatGptQuery(msg):
    config = configparser.ConfigParser()
    config.read("../LINEBOT_API_KEY/openai_api.ini")
    key = config.get("openai", "key")
    try:
        # å–å‡ºæ–‡å­—çš„å‰äº”å€‹å­—å…ƒï¼Œè½‰æ›æˆå°å¯«
        # å°‡ç¬¬å…­å€‹å­—å…ƒä¹‹å¾Œçš„è¨Šæ¯ç™¼é€çµ¦ OpenAI
        ai_msg = msg[:6].lower()
        reply_msg = ""
        # å–å‡ºæ–‡å­—çš„å‰äº”å€‹å­—å…ƒæ˜¯ hi ai:
        if ai_msg == "hi ai:":
            msg = msg[6:]
            print(len(encoding.encode(msg)))
            if len(encoding.encode(msg)) > max_tokens:
                msg_token = encoding.encode(msg)[:max_tokens]
                print(len(msg_token))
                msg = encoding.decode(msg_token)
                # msg = [encoding.decode_single_token_bytes(token) for token in msg_token]
            print(msg)
            # # è¨­å®š OpenAI API é‡‘é‘°
            client = OpenAI(api_key=key)
            response = client.completions.create(
                # model="gpt-3.5-turbo-instruct",
                model="text-davinci-003",
                # å°‡ç¬¬å…­å€‹å­—å…ƒä¹‹å¾Œçš„è¨Šæ¯ç™¼é€çµ¦ OpenAI
                # prompt=msg[6:],
                prompt=msg + "\nè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸è¦è¶…é150å­—èªªæ˜ã€‚",
                max_tokens=500,
                temperature=0.8,
                frequency_penalty=0.5,
                presence_penalty=0.3,
            )
            # æ¥æ”¶åˆ°å›è¦†è¨Šæ¯å¾Œï¼Œç§»é™¤æ›è¡Œç¬¦è™Ÿ
            msg = response.choices[0].text.replace("\n", "")
            print(msg)
            return msg
        else:
            msg = "å¤±æ•—äº†"
        return msg
    except Exception as e:
        print(f"Error with vendor_id : {e}")
    return "OK"


if __name__ == "__main__":
    result = ChatGptCommitQuery(
        "hi ai:'å:La æ³•åŒ…,åœ°å€:å°åŒ—å¸‚å¤§å®‰å€å»¶å‰è¡—137å··25è™Ÿ1æ¨“,é¤é»åç¨±:æ³•å¼è¶Šå—éºµåŒ…å«é£²æ–™banh mi+drink,åº—å®¶è©•åƒ¹:è²·äº†é›è…¿å£å‘³çš„éºµåŒ…ï¼ŒéºµåŒ…é…¥è„†ï¼Œå¯ä»¥åˆ‡å°åŠé¦™æ–™é›è…¿å¥½åƒğŸ˜‹ä»½é‡ä¸­ç­‰ï¼Œé£Ÿæ…¾æ¯”è¼ƒå¥½çš„ä¸­åˆå¯èƒ½è¦åƒå…©ä»½æ¯”è¼ƒé£½ åƒäº†è„†çš®ç‡’è‚‰å£å‘³+å¥¶èŒ¶"
    )
